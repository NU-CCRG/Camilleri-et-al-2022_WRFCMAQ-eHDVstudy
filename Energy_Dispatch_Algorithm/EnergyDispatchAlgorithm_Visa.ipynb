{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, Point, MultiPolygon, shape\n",
    "import fiona\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and read-in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mav5149/.conda/envs/mvenviro/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0,3,5,7,14,15,17,18,19,20,24,26,31,47,48,49,51,52,55,56,57,58,60,61,62,64,65,84,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/mav5149/.conda/envs/mvenviro/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (12,25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Open Plant Dataset\n",
    "county_fips = pd.read_csv('county_fips.csv')\n",
    "fips = np.array(county_fips).tolist()\n",
    "\n",
    "#Import NERC Shapefiles\n",
    "nerc = gpd.read_file('NERC_regions/NercRegions_201907.shp')\n",
    "\n",
    "#Import EGU Datafile\n",
    "#Remove non-contigous states\n",
    "egu = pd.read_csv('eGRID_plnt16.csv')\n",
    "egu.drop(egu[egu['Plant state abbreviation'] == 'AK'].index, inplace = True)\n",
    "egu.drop(egu[egu['Plant state abbreviation'] == 'HI'].index, inplace = True)\n",
    "#Remove header row\n",
    "egu = egu[1:]\n",
    "\n",
    "#Import GENERATOR Egu file\n",
    "egen = pd.read_csv('egrid2016_gen16.csv')\n",
    "egen.drop(egen[egen['Plant state abbreviation'] == 'AK'].index, inplace = True)\n",
    "egen.drop(egen[egen['Plant state abbreviation'] == 'HI'].index, inplace = True)\n",
    "#Remove header row\n",
    "egen = egen[1:]\n",
    "\n",
    "#Import County Shapefiles\n",
    "#We need county shapefiles to determine what counties lie within which NERC region\n",
    "counties = gpd.read_file('CONUS_shp/US_county_2018.shp')\n",
    "counties = counties.to_crs(\"EPSG:4326\")\n",
    "\n",
    "#California VMT file\n",
    "caVMT = pd.read_csv('california_vmt.csv')\n",
    "caVMT = np.array(caVMT).tolist()\n",
    "\n",
    "#Smoke File import\n",
    "smoke_file = Dataset('inln_mole_ptegu_20160101_CONUS4K_d02_cmaq_cb6_2016ff_16j.ncf')\n",
    "smoke_egu = Dataset('stack_groups_ptegu_CONUS4K_d02_2016ff_16j.ncf')\n",
    "vmt_data = pd.read_csv('VMT_tail+29.csv')\n",
    "vmt_full = np.array(vmt_data).tolist()\n",
    "vmt_full.insert(0, ['US', 32003, 'nan', 'nan', 'nan', 2201110200, 'nan', 'nan', 'VMT', 220929.239490000007, 2016, 20180727, '2016_beta_state_via_CSRA', 5788.78808279999976, 5235.13920520000011, 12886.3604529999993, 22248.9007889999993, 26376.5204339999982, 28037.6888719999988, 29447.2156009999999, 29799.5989300000001, 25017.5850839999985, 20990.486488999999, 9765.29365160000089, 5335.66190009999991, 'c32003y2014_20170911  Results assume the CDB  has the new  HPMS system. No conversion of HPMS.'])\n",
    "vmt_full.insert(0, ['country_cd', 'region_cd', 'tribal_code', 'census_tract_cd', 'shape_id', 'scc', 'act_parm_type_cd', 'act_parm_uofmsr', 'activity_type', 'ann_parm_value', 'calc_year', 'date_updated', 'data_set_id', 'jan_value', 'feb_value', 'mar_value', 'apr_value', 'may_value', 'jun_value', 'jul_value', 'aug_value', 'sep_value', 'oct_value', 'nov_value', 'dec_value', 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Determine proportion of renewable electricity generated by each NERC region\n",
    "egen = np.array(egen).tolist()\n",
    "egu = np.array(egu).tolist()\n",
    "\n",
    "mro = [i for i in egu if i[10] == 'MRO']\n",
    "npcc = [i for i in egu if i[10] == 'NPCC']\n",
    "rfc = [i for i in egu if i[10] == 'RFC']\n",
    "serc = [i for i in egu if i[10] == 'SERC' or i[10] == 'FRCC']\n",
    "spp = [i for i in egu if i[10] == 'SPP']\n",
    "tre = [i for i in egu if i[10] == 'TRE']\n",
    "wecc = [i for i in egu if i[10] == 'WECC']\n",
    "\n",
    "nercs = [mro, npcc, rfc, serc, spp, tre, wecc]\n",
    "\n",
    "fracs_by_nerc = []\n",
    "for i in nercs:\n",
    "    renew_frac = []\n",
    "    non_renew_frac = []\n",
    "    for n in i:\n",
    "        if n[22] == 'SOLAR' or n[22] == 'WIND' or n[22] == 'HYDRO' or n[22] == 'GEOTHERMAL':\n",
    "            renew_frac.append(n[37])\n",
    "        else:\n",
    "            non_renew_frac.append(n[37])\n",
    "    r = []\n",
    "    nr = []\n",
    "    for i in renew_frac:\n",
    "        if type(i) == float:\n",
    "            pass\n",
    "        elif ',' in i:\n",
    "            r.append(int(i.replace(',', '')))\n",
    "        elif i != 'nan':\n",
    "            r.append(int(i))\n",
    "    for i in non_renew_frac:\n",
    "        if type(i) == float:\n",
    "            pass\n",
    "        elif ',' in i:\n",
    "            nr.append(int(i.replace(',', '')))\n",
    "        elif ',' not in i and i != 'nan':\n",
    "            nr.append(int(i))\n",
    "    r_percent = (sum(nr) / ((sum(r)) + sum(nr)))\n",
    "    fracs_by_nerc.append(r_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove any/all powerplants and generators who's ORIS code is not in SMOKE's inventory, per ptegu_list_2016.\n",
    "#Add back in nuclear EGU's\n",
    "\n",
    "ptegu_list = pd.read_csv('ptegu_list_2016.csv')\n",
    "ptegu_list = np.array(ptegu_list).tolist()\n",
    "discrete_ptegus = []\n",
    "for i in ptegu_list:\n",
    "    if str(i[4]) not in discrete_ptegus:\n",
    "        discrete_ptegus.append(str(i[4]))\n",
    "nuc_oris = []\n",
    "for i in egu:\n",
    "    if i[22] == 'NUCLEAR':\n",
    "        discrete_ptegus.append(str(i[3]))\n",
    "        nuc_oris.append(str(i[3]))\n",
    "\n",
    "new_egu = []\n",
    "for i in egu:\n",
    "    if str(i[3]) in discrete_ptegus:\n",
    "        new_egu.append(i)\n",
    "        \n",
    "new_egen = []\n",
    "for i in egen:\n",
    "    if str(i[3]) in discrete_ptegus:\n",
    "        new_egen.append(i)\n",
    "        \n",
    "egu = new_egu\n",
    "egen = new_egen\n",
    "\n",
    "del new_egu\n",
    "del new_egen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add powerplant age (compiled by averaging all generators of a powerplant) for age weight later on.\n",
    "#If no age, use 1982 average since that is current egu age per EIA.\n",
    "\n",
    "tally = []\n",
    "for i in egu:\n",
    "    m = []\n",
    "    m.append(str(i[3]))\n",
    "    tally.append(m)\n",
    "\n",
    "numbers = []\n",
    "for i in egen:\n",
    "    l = []\n",
    "    k = i[3]\n",
    "    m = i[14]\n",
    "    l.append(k)\n",
    "    l.append(m)\n",
    "    numbers.append(l)\n",
    "\n",
    "\n",
    "for i in tally:\n",
    "    m = []\n",
    "    for n in numbers:\n",
    "        if i[0] == n[0]:\n",
    "            m.append(n[1])\n",
    "    int_list = []\n",
    "    for q in m:\n",
    "        if len(str(q)) == 4:\n",
    "            int_list.append(int(q))\n",
    "    if len(int_list) == 0:\n",
    "        i.append(1982)\n",
    "    else:\n",
    "        average = sum(int_list)/len(int_list)\n",
    "        i.append(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Electric Vehicle Adoption Scenario\n",
    "ev_penetration = .3 # Depending on experimental scenario\n",
    "grid_loss = .051 #5.1% Energy is lost in transmission through the energy grid per 2019 EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vehicle efficiencies MWh/mile\n",
    "eff_41 = .001613 # Ebusco 2.2 \n",
    "eff_42 = .002006 # Proterra ZX5\n",
    "eff_43 = .0013548 # Lion Electric (155-mile range)\n",
    "eff_51 = .0019764 # Lion8 Refuse Truck\n",
    "eff_52 = .002 # Tesla Semi\n",
    "eff_53 = .002 # Tesla Semi\n",
    "eff_54 = .0004337 # WOF Iridium\n",
    "eff_61 = .002 # Tesla Semi\n",
    "eff_62 = .002 # Tesla Semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pull Out relevant SCC Codes from VMT file\n",
    "all_scc = []\n",
    "for i in vmt_full:\n",
    "    if str(i[5]) not in all_scc:\n",
    "        all_scc.append(str(i[5]))\n",
    "#Turn string SCCs into integers and rename twice lol.\n",
    "ld_scc = all_scc[1:]\n",
    "for i in range(len(ld_scc)):\n",
    "    ld_scc[i] = int(ld_scc[i])\n",
    "scc_codes = ld_scc\n",
    "\n",
    "#Add california counties to VMT_full\n",
    "for i in caVMT:\n",
    "    vmt_full.append(i)\n",
    "\n",
    "#This does nothing. Keep as relic of my stupidity. xoxo -MAV\n",
    "vmt_ldv = []\n",
    "for i in vmt_full:\n",
    "    for n in scc_codes:\n",
    "        if i[5] == n:\n",
    "            vmt_ldv.append(i)\n",
    "            \n",
    "            \n",
    "vmt_ldv.insert(0, ['country_cd', 'region_cd', 'tribal_code', 'census_tract_cd', 'shape_id', 'scc', 'act_parm_type_cd', 'act_parm_uofmsr', 'activity_type', 'ann_parm_value', 'calc_year', 'date_updated', 'data_set_id', 'jan_value', 'feb_value', 'mar_value', 'apr_value', 'may_value', 'jun_value', 'jul_value', 'aug_value', 'sep_value', 'oct_value', 'nov_value', 'dec_value', 'comment'])\n",
    "#Delete large datasets to clear up memory\n",
    "del caVMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Combine All SCC's to create 1 VMT total per county\n",
    "county_ids_long = []\n",
    "for i in vmt_ldv:\n",
    "    if i[1] not in county_ids_long:\n",
    "        county_ids_long.append(i[1])\n",
    "county_ids_long = county_ids_long[1:]\n",
    "county_ids = []\n",
    "for i in county_ids_long:\n",
    "    county_list = []\n",
    "    county_list.append(i)\n",
    "    county_ids.append(county_list)\n",
    "for i in county_ids:\n",
    "    for n in vmt_ldv:\n",
    "        if n[1] == i[0]:\n",
    "            if str(n[5])[4:6] == '41':\n",
    "                i.append((n[9]*ev_penetration*eff_41)/(1 - grid_loss))\n",
    "            elif str(n[5])[4:6] == '42':\n",
    "                i.append((n[9]*ev_penetration*eff_42)/(1 - grid_loss))\n",
    "            elif str(n[5])[4:6] == '43':\n",
    "                i.append((n[9]*ev_penetration*eff_43)/(1 - grid_loss))   \n",
    "            elif str(n[5])[4:6] == '51':\n",
    "                i.append((n[9]*ev_penetration*eff_51)/(1 - grid_loss))\n",
    "            elif str(n[5])[4:6] == '52' or str(n[5])[4:6] == '53' or str(n[5])[4:6] == '61' or str(n[5])[4:6] == '62':\n",
    "                i.append((n[9]*ev_penetration*eff_52)/(1 - grid_loss))\n",
    "            elif str(n[5])[4:6] == '54':\n",
    "                i.append((n[9]*ev_penetration*eff_54)/(1 - grid_loss))\n",
    "\n",
    "county_vmt = []\n",
    "for i in county_ids:\n",
    "    county_data = []\n",
    "    county_data.append(i[0])\n",
    "    total_cvmt = sum(i[1:])\n",
    "    county_data.append(total_cvmt)\n",
    "    county_vmt.append(county_data)\n",
    "    \n",
    "#Delete large datasets to clear up memory\n",
    "#del county_ids_long\n",
    "#del county_ids\n",
    "#del county_list\n",
    "#del county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Relate FIPS code back to Region_ID and state of county in vmt file\n",
    "for i in county_vmt:\n",
    "    for n in fips:\n",
    "        if i[0] == n[0]:\n",
    "            i.insert(1, n[2])\n",
    "            i.insert(1, n[1])\n",
    "#Add Header for clarification\n",
    "#county_vmt.insert(0, ['FIPS Code', 'County Name', 'County State', 'Total non-E VMT', \"EV-Converted VMT\", 'Added mWh'])\n",
    "point = Point(-102.6216, 43.2347)\n",
    "county_vmt[1763].insert(1, 'Shannon County')\n",
    "county_vmt[1763].insert(2, 'South Dakota')\n",
    "#county_vmt[1764].insert(6, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910\n"
     ]
    }
   ],
   "source": [
    "egu_nerc = []\n",
    "for i in egu:\n",
    "    single_egu = []\n",
    "    if i[10] == 'MRO':\n",
    "        single_egu.append([i[3], i[17], i[18],1,0,0,0,0,0,0])\n",
    "    elif i[10] == 'NPCC':\n",
    "        single_egu.append([i[3], i[17], i[18],0,1,0,0,0,0,0])\n",
    "    elif i[10] == 'RFC':\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,1,0,0,0,0])\n",
    "    elif i[10] == 'SERC': \n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,1,0,0,0])\n",
    "    elif i[10] == 'FRCC':\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,1,0,0,0])\n",
    "    elif i[10] == 'SPP':\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,0,1,0,0])\n",
    "    elif i[10] == 'TRE':\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,0,0,1,0])\n",
    "    elif i[10] == 'WECC':\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,0,0,0,1])\n",
    "    else:\n",
    "        single_egu.append([i[3], i[17], i[18],0,0,0,0,0,0,0])\n",
    "    egu_nerc.append(single_egu)\n",
    "nerccy = []\n",
    "for i in egu_nerc:\n",
    "    nerccy.append(i[0])\n",
    "egu_nerc = nerccy\n",
    "print(len(egu_nerc))\n",
    "egu_nerc = pd.DataFrame(egu_nerc)\n",
    "egu_nerc.columns = ['PFC', 'Lat', 'Lon', 'MRO', 'NPCC', 'RFC', 'SERC', 'SPP', 'TRE', 'WECC',]\n",
    "nerc_egu = egu_nerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = counties.to_crs(\"EPSG:4326\")\n",
    "county_centroids = [(counties['geometry'][i]).centroid for i in range(len(counties['geometry']))]\n",
    "\n",
    "nerc = gpd.read_file('NERC_regions/NercRegions_201907.shp')\n",
    "\n",
    "nerc_counties = []\n",
    "for county in county_centroids:\n",
    "    county_list = []\n",
    "    for poly in nerc['geometry']:\n",
    "        if poly.contains(county):\n",
    "            county_list.append(1)\n",
    "        else:\n",
    "            county_list.append(0)\n",
    "    nerc_counties.append(county_list)\n",
    "\n",
    "m = np.array(counties).tolist()\n",
    "for i in range(len(nerc_counties)):\n",
    "    nerc_counties[i].insert(0, m[i][6])\n",
    "    nerc_counties[i].insert(0, m[i][4])\n",
    "    \n",
    "nerc_counties = pd.DataFrame(nerc_counties)\n",
    "nerc_counties.columns = ['FIPS', 'County', 'MRO', 'NPCC', 'RFC', 'SERC', 'SPP', 'TRE', 'WECC', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import coded and csv'ed nerc_county weights file.\n",
    "nerc_counties = np.array(nerc_counties).tolist()\n",
    "for i in nerc_counties:\n",
    "    if len(str(i[0])) == 4:\n",
    "        new_fips = ('0' + str(i[0]))\n",
    "        i[0] = new_fips\n",
    "\n",
    "#Now let's delete the last column since it's got nothing\n",
    "for i in nerc_counties:\n",
    "    del i[-1]\n",
    "\n",
    "for i in nerc_counties:\n",
    "    string_vers = str(i[0])\n",
    "    i[0] = string_vers\n",
    "\n",
    "#Fixing Counties that are in between Nerc regions:\n",
    "\n",
    "#05005-05147 Counties in Arkansas are being manually rerouted to SERC\n",
    "#19007-19185 Counties in Iowa are being manually rerouted to MRO\n",
    "#29003-29227 Counties in Missouri are being manually rerouted to SERC\n",
    "#40001-40147 Counties in Oklahoma are being manually rerouted to SPP\n",
    "#11001 County is Washington DC and goes in RFC\n",
    "#23023 is Sagadahoc County and goes in Maine in NPCC\n",
    "#26083-26115 are in Michigan and go in RFC\n",
    "#34017 is Hudson County in NJ and belongs in RFC\n",
    "#37133 and 37137 are counties in NC and belong in SERC\n",
    "#44005 is Newport County in RI and belongs in NPCC\n",
    "#55079 and 55089 are WI counties and belong in RFC\n",
    "for i in nerc_counties:\n",
    "    if i[2:9] == [0,0,0,0,0,0,0]:\n",
    "        if i[0][0] == '0' and i[0][1] == '5':\n",
    "            i[5] = 1\n",
    "        if i[0][0] == '1' and i[0][1] == '9':\n",
    "            i[2] = 1\n",
    "        if i[0][0] == '2' and i[0][1] == '9':\n",
    "            i[5] = 1\n",
    "        if i[0][0] == '4' and i[0][1] == '0':\n",
    "            i[6] = 1\n",
    "        if i[0] == '11001':\n",
    "            i[4] = 1\n",
    "        if i[0] == '23023':\n",
    "            i[3] = 1\n",
    "        if i[0][0] == '2' and i[0][1] == '6':\n",
    "            i[4] = 1\n",
    "        if i[0] == '34017':\n",
    "            i[4] = 1\n",
    "        if i[0][0] == '3' and i[0][1] == '7':\n",
    "            i[5] = 1\n",
    "        if i[0] == '44005':\n",
    "            i[3] = 1\n",
    "        if i[0][0] == '5' and i[0][1] == '5':\n",
    "            i[4] = 1\n",
    "\n",
    "nerc_counties = pd.DataFrame(nerc_counties)\n",
    "nerc_counties.columns = ['FIPS', 'County', 'MRO', 'NPCC', 'RFC', 'SERC', 'SPP', 'TRE', 'WECC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create EGU and COUNTY skeletons to ultimately make county x egu array.\n",
    "#County skeleton array\n",
    "county_array = np.array(nerc_counties).tolist()\n",
    "counties_array = np.array(counties).tolist()\n",
    "county_skel = [[i[4], (i[20]).centroid] for i in counties_array]\n",
    "for i in range(len(nerc_counties)):\n",
    "    if county_array[i][2] == 1:\n",
    "        county_skel[i].insert(2, 1)\n",
    "    elif county_array[i][3] == 1:\n",
    "        county_skel[i].insert(2, 2)\n",
    "    elif county_array[i][4] == 1:\n",
    "        county_skel[i].insert(2, 3)\n",
    "    elif county_array[i][5] == 1:\n",
    "        county_skel[i].insert(2, 4)\n",
    "    elif county_array[i][6] == 1:\n",
    "        county_skel[i].insert(2, 5)\n",
    "    elif county_array[i][7] == 1:\n",
    "        county_skel[i].insert(2, 6)\n",
    "    elif county_array[i][8] == 1:\n",
    "        county_skel[i].insert(2, 7)\n",
    "    else:\n",
    "        county_skel[i].insert(2, 'None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#EGU Skeleton array\n",
    "egu_array = np.array(nerc_egu).tolist()\n",
    "egu = np.array(egu).tolist()\n",
    "\n",
    "egu_skel = [[egu[i][3], Point(float(egu[i][18]),float(egu[i][17]))] for i in range(len(egu))]\n",
    "for i in range(len(nerc_egu)):\n",
    "    if egu_array[i][3] == 1:\n",
    "        egu_skel[i].insert(2, 1)\n",
    "    elif egu_array[i][4] == 1:\n",
    "        egu_skel[i].insert(2, 2)\n",
    "    elif egu_array[i][5] == 1:\n",
    "        egu_skel[i].insert(2, 3)\n",
    "    elif egu_array[i][6] == 1:\n",
    "        egu_skel[i].insert(2, 4)\n",
    "    elif egu_array[i][7] == 1:\n",
    "        egu_skel[i].insert(2, 5)\n",
    "    elif egu_array[i][8] == 1:\n",
    "        egu_skel[i].insert(2, 6)\n",
    "    elif egu_array[i][9] == 1:\n",
    "        egu_skel[i].insert(2, 7)\n",
    "    else:\n",
    "        egu_skel[i].insert(2, 'None')\n",
    "\n",
    "#Delete large datasets to clear up memory\n",
    "del egu_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create large array that has as many rows as counties and columns as egu's.\n",
    "#Note that if a county and egu are not in the same NERC region, their intersect will have a '0'.\n",
    "\n",
    "#create list of shapely points because the points in egu and county skel are of type str and not shapely geometry (for .distance operation)\n",
    "\n",
    "egu_coords = [Point(float(egu[i][18]),float(egu[i][17])) for i in range(len(egu))]\n",
    "county_coords = [(i[20]).centroid for i in counties_array]\n",
    "\n",
    "egu_skel = np.array(egu_skel).tolist()\n",
    "county_skel = np.array(county_skel).tolist()\n",
    "distance_weight = []\n",
    "for i in range(len(county_skel)):\n",
    "    county_weight = []\n",
    "    for n in range(len(egu_skel)):\n",
    "        if len(county_skel[i][2]) <= 2 and str(county_skel[i][2]) == str(egu_skel[n][2]):\n",
    "            inv_distance = 1/(county_coords[i].distance(egu_coords[n]))\n",
    "            county_weight.append(inv_distance)\n",
    "        else:\n",
    "            county_weight.append(0)\n",
    "    distance_weight.append(county_weight)\n",
    "\n",
    "#Delete large datasets to clear up memory\n",
    "del county_coords\n",
    "del egu_skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Multiply the added MWh per county in the county_vmt file by 1-(renewability fraction) for a county in each nerc reg.\n",
    "\n",
    "all_county_nerc = []\n",
    "for i in county_skel:\n",
    "    if i[2] == 'None':\n",
    "        pass\n",
    "    else:\n",
    "        bucket = []\n",
    "        bucket.append(int(i[0]))\n",
    "        bucket.append(int(i[2]))\n",
    "    all_county_nerc.append(bucket)\n",
    "\n",
    "for i in county_vmt:\n",
    "    for n in all_county_nerc:\n",
    "        if i[0] == n[0]:\n",
    "            new_mwh = i[-1] * fracs_by_nerc[(n[1])-1]\n",
    "            i[-1] = new_mwh\n",
    "\n",
    "del county_skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalize the weights so that all of the weights for a single county add up to 1.\n",
    "total_list = []\n",
    "for i in distance_weight:\n",
    "    total = sum(i)\n",
    "    total_list.append(total)\n",
    "for i in range(len(total_list)):\n",
    "    for n in range(len(distance_weight[i])):\n",
    "        if total_list[i] > 0:\n",
    "            normalized_weight = distance_weight[i][n] / total_list[i]\n",
    "            distance_weight[i][n] = normalized_weight\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "#Delete large datasets to clear up memory\n",
    "del total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we make the intensity weight! One list with all EGU intensities that will be multiplied over the distance weight.\n",
    "egu = np.array(egu).tolist()\n",
    "egu_capfac = [i[24] for i in egu]\n",
    "\n",
    "#Capfac is a list of percent capacity for all EGU's, if %cap is 1, that means the EGU is out of order, simulated by a 100% capacity and thus cannot generate more elec.\n",
    "#This will also zero out its value in the distance_weight array when multiplied by 0 and render it as a non-generating unit, as it should be.\n",
    "capfac = []\n",
    "for i in egu_capfac:\n",
    "    if i == 'nan' or i == '0.0000':\n",
    "        m = 1\n",
    "        capfac.append(m)\n",
    "    else:\n",
    "        floated = float(i)\n",
    "        capfac.append(floated)\n",
    "\n",
    "intensity_weight = []\n",
    "for i in capfac:\n",
    "    availability = 1 - i\n",
    "    intensity_weight.append(availability)\n",
    "egu_ng = []\n",
    "for i in egu:\n",
    "    if i[37] == 'nan':\n",
    "        egu_ng.append(0)\n",
    "    else:\n",
    "        egu_ng.append(float(i[37].replace(',', '')))\n",
    "    \n",
    "#Multiply by net generation to make room weight. Then multiply by non-baseload factor bc we want to use marginal demand.\n",
    "room_list = []\n",
    "for i in range(len(intensity_weight)):\n",
    "    room = intensity_weight[i] * egu_ng[i] #* egu_nbf[i]\n",
    "    room_list.append(room)\n",
    "intensity_weight = room_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we multiply the capacity factor for each EGU by that EGU's distance weight to create our (almost, not normalized) final weight array!\n",
    "final_weight = []\n",
    "for county in distance_weight:\n",
    "    county_weight = [(county[i] * intensity_weight[i]) for i in range(len(county))]\n",
    "    final_weight.append(county_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create Age weight.\n",
    "\n",
    "#Then, create list of 7418 numbers per the dataset we are using, each number being the year each EGU started operating. In order, as always. \n",
    "#Subtract from 2021 to get age.\n",
    "year_list = []\n",
    "for i in tally:\n",
    "    year_list.append(2021 - i[1])\n",
    "            \n",
    "#Divide the weight by the age. Older EGU's get a smaller weight, newer ones a larger weight.\n",
    "final_weights = []\n",
    "for i in final_weight:\n",
    "    list_one = []\n",
    "    for n in range(len(year_list)):\n",
    "        weight = (i[n] / year_list[n])\n",
    "        list_one.append(weight)\n",
    "    final_weights.append(list_one)\n",
    "final_weight = final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we normalize the almost final weight array to get our ACTUAL final weight array! Woo!\n",
    "totals = []\n",
    "for i in final_weight:\n",
    "    county_total = sum(i)\n",
    "    totals.append(county_total)\n",
    "for i in range(len(totals)):\n",
    "    for n in range(len(final_weight[i])):\n",
    "        if totals[i] > 0:\n",
    "            normalized_weight = final_weight[i][n] / totals[i]\n",
    "            final_weight[i][n] = normalized_weight\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "#Delete large datasets to clear up memory\n",
    "del distance_weight\n",
    "del intensity_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Multiply weight factor by county vmt's\n",
    "counties = np.array(counties)\n",
    "distributed_energy = []\n",
    "for i in range(len(counties)):\n",
    "    fips1 = int(counties[i][4])\n",
    "    for n in county_vmt:\n",
    "        fips2 = n[0]\n",
    "        if fips1 == fips2:\n",
    "            single_county = [m * n[-1] for m in final_weight[i]]\n",
    "    distributed_energy.append(single_county)\n",
    "    \n",
    "#Delete large datasets to clear up memory\n",
    "del final_weight\n",
    "del final_weights\n",
    "del counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sum all of the columns to get a net added MWh per EGU in the U.S.\n",
    "added_egu = []\n",
    "for i in range(len(distributed_energy[0])):\n",
    "    egu_numbers = []\n",
    "    for n in range(len(distributed_energy)):\n",
    "        single_egu = distributed_energy[n][i]\n",
    "        egu_numbers.append(single_egu)\n",
    "    added_egu.append(sum(egu_numbers))\n",
    "\n",
    "#Delete large datasets to clear up memory\n",
    "del distributed_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First column = added energy, second is total produced by powerplant.\n",
    "for i in range(len(added_egu)):\n",
    "    total_mwh = egu[i][37]\n",
    "    plant_list = [added_egu[i]]\n",
    "    nox_emis = egu[i][39]\n",
    "    if total_mwh == 'nan' or total_mwh == '0':\n",
    "        added_percentage = 0\n",
    "    else:\n",
    "        if ',' in total_mwh:\n",
    "            total_mwh = total_mwh.replace(',','')\n",
    "        total_mwh = int(total_mwh)\n",
    "        added_percentage = (added_egu[i] / total_mwh)\n",
    "    plant_list.append(total_mwh)\n",
    "    plant_list.append(added_percentage)\n",
    "    plant_list.append(egu[i][24])\n",
    "    plant_list.append(str(egu[i][3]))\n",
    "    plant_list.append(egu[i][22])\n",
    "    plant_list.append(egu[i][17])\n",
    "    plant_list.append(egu[i][18])\n",
    "    added_egu[i] = plant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.631830e+04</td>\n",
       "      <td>439412</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>54429</td>\n",
       "      <td>BIOMASS</td>\n",
       "      <td>31.5825</td>\n",
       "      <td>-87.4889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.010015e+04</td>\n",
       "      <td>46242</td>\n",
       "      <td>0.434673</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>56018</td>\n",
       "      <td>GAS</td>\n",
       "      <td>33.1661</td>\n",
       "      <td>-86.2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.086699e+06</td>\n",
       "      <td>12770891</td>\n",
       "      <td>0.085092</td>\n",
       "      <td>0.5131</td>\n",
       "      <td>3</td>\n",
       "      <td>COAL</td>\n",
       "      <td>31.0069</td>\n",
       "      <td>-88.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.589362e+05</td>\n",
       "      <td>26214623</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>46</td>\n",
       "      <td>NUCLEAR</td>\n",
       "      <td>34.7042</td>\n",
       "      <td>-87.1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.479949e+04</td>\n",
       "      <td>195125</td>\n",
       "      <td>0.434591</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>55409</td>\n",
       "      <td>GAS</td>\n",
       "      <td>33.5883</td>\n",
       "      <td>-85.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1.082382e+03</td>\n",
       "      <td>5309</td>\n",
       "      <td>0.203877</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>55477</td>\n",
       "      <td>GAS</td>\n",
       "      <td>44.285</td>\n",
       "      <td>-105.3786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1.617666e+04</td>\n",
       "      <td>710524</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>55479</td>\n",
       "      <td>COAL</td>\n",
       "      <td>44.2858</td>\n",
       "      <td>-105.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>2.750602e+04</td>\n",
       "      <td>734354</td>\n",
       "      <td>0.037456</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>56319</td>\n",
       "      <td>COAL</td>\n",
       "      <td>44.2919</td>\n",
       "      <td>-105.3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>5.918815e+04</td>\n",
       "      <td>821699</td>\n",
       "      <td>0.072031</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>56596</td>\n",
       "      <td>COAL</td>\n",
       "      <td>44.2919</td>\n",
       "      <td>-105.3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>8.250539e+04</td>\n",
       "      <td>2056358</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>6101</td>\n",
       "      <td>COAL</td>\n",
       "      <td>44.290128</td>\n",
       "      <td>-105.381482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1910 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2       3      4        5          6  \\\n",
       "0     2.631830e+04    439412  0.059894  0.7270  54429  BIOMASS    31.5825   \n",
       "1     2.010015e+04     46242  0.434673  0.0535  56018      GAS    33.1661   \n",
       "2     1.086699e+06  12770891  0.085092  0.5131      3     COAL    31.0069   \n",
       "3     6.589362e+05  26214623  0.025136  0.8565     46  NUCLEAR    34.7042   \n",
       "4     8.479949e+04    195125  0.434591  0.0298  55409      GAS    33.5883   \n",
       "...            ...       ...       ...     ...    ...      ...        ...   \n",
       "1905  1.082382e+03      5309  0.203877  0.0152  55477      GAS     44.285   \n",
       "1906  1.617666e+04    710524  0.022767  0.9012  55479     COAL    44.2858   \n",
       "1907  2.750602e+04    734354  0.037456  0.8824  56319     COAL    44.2919   \n",
       "1908  5.918815e+04    821699  0.072031  0.8086  56596     COAL    44.2919   \n",
       "1909  8.250539e+04   2056358  0.040122  0.5835   6101     COAL  44.290128   \n",
       "\n",
       "                7  \n",
       "0        -87.4889  \n",
       "1        -86.2825  \n",
       "2        -88.0103  \n",
       "3        -87.1189  \n",
       "4        -85.9731  \n",
       "...           ...  \n",
       "1905    -105.3786  \n",
       "1906    -105.3833  \n",
       "1907    -105.3811  \n",
       "1908    -105.3806  \n",
       "1909  -105.381482  \n",
       "\n",
       "[1910 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(added_egu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For LADCO runs:\n",
    "\n",
    "ptegu_2k18 = pd.read_csv('ptegu_list_2018.csv')\n",
    "ptegu_2k18 = np.array(ptegu_2k18).tolist()\n",
    "refinery = []\n",
    "for i in ptegu_2k18:\n",
    "    if i[-1] not in refinery:\n",
    "        refinery.append(i[-1])\n",
    "        \n",
    "new_csv = []\n",
    "for i in added_egu:\n",
    "    if int(i[4]) in refinery:\n",
    "        new_csv.append(i)\n",
    "pd.DataFrame(new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "mvenviro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
